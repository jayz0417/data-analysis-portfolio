{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNOWUmdUIz17"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê°œìš”\n",
        "1. ì œì£¼ ì „ì²´ì˜ ë§¤ì¶œê³¼ ì´ìµ ê°œì„ ì„ ìœ„í•´ ë¶€ë¦„ ì§€ì—­ì„ í™•ëŒ€í•˜ê³  ë¶€ë¦„ íŽ¸ë„ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì˜¤í”ˆí•œë‹¤\n",
        "- ëª©í‘œ : ê¸°ì¡´ì˜ ì „ì²´ ê±´ìˆ˜ì—ì„œ ì™•ë³µ ì˜ˆì•½ ë¹„ì¤‘ì€ ìœ ì§€í•˜ë©´ì„œ, ë¶€ë¦„ìœ¼ë¡œ ì¸í•œ ê±´ìˆ˜ë¥¼ 3% ì¦ê°€ ì‹œí‚¨ë‹¤"
      ],
      "metadata": {
        "id": "nQJEJVLHI-sG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì‚´íŽ´ë³´ê¸°\n",
        "1. ì œì£¼ì§€ì—­ì˜ ë¶€ë¦„ ìš´ì˜ ì‹œìž‘ì´í›„ ì™•ë³µ ì˜ˆì•½ ë¹„ì¤‘ì€ ìœ ì§€ë˜ê³  ìžˆëŠ”ì§€ ?   \n",
        "1-1 ì „ì²´ ê±´ìˆ˜ëŠ” ì¦ê°€ í•˜ì˜€ëŠ”ì§€ ?\n",
        "- ê±´ìˆ˜\n",
        "- ë§¤ì¶œ\n",
        "- ì´ìµ(GP)\n",
        "3. ì§€ì—­ë³„ í˜„í™©ì€ ì–´ë– í•œì§€\n",
        "- ì œì£¼ì‹œ\n",
        "- ì„œê·€í¬ì‹œ\n",
        "4. ë” ê°œì„ í•  ìˆ˜ ìžˆëŠ” ë¶€ë¶„ì€ ì–´ë””ì¸ì§€"
      ],
      "metadata": {
        "id": "u5J016dBI_Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "5Tyx3S_5A8KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GolvqokrI_dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ â³"
      ],
      "metadata": {
        "id": "vcs8RpCZI_vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "Q6Yl4Fo_KxEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í•„ìš”í•œ ë°ì´í„°ë¥¼ ë¹…ì¿¼ë¦¬ì— ì—°ë™í•˜ì—¬ ê°€ì ¸ì˜´\n",
        "* ë¶€ë¦„ ìš´ì˜ ì „í›„ 4ì£¼ê°„ì˜ ì‹¤ì  ë¹„êµ"
      ],
      "metadata": {
        "id": "NXLZ8sF6KrTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "  SELECT\n",
        "      CASE WHEN date >= '2023-11-06' AND date <= '2023-12-07' THEN 'As-is'\n",
        "           WHEN date >= '2023-12-08' AND date <= '2024-01-08' THEN 'To-be' END as date\n",
        "      , r.way as way\n",
        "      , r.region2\n",
        "\n",
        "      , count(r.reservation_id) as nuse -- ì˜ˆì•½ê±´ìˆ˜\n",
        "      , sum(r.utime) as utime -- ì´ìš©ì‹œê°„\n",
        "\n",
        "      , sum(revenue) as revenue -- íšŒê³„ë§¤ì¶œ\n",
        "      , sum(_rev_d2d) as _rev_d2d -- ë¶€ë¦„ë§¤ì¶œ(ë¶€ë¦„ìš”ê¸ˆ + íŽ¸ë„ìš”ê¸ˆ)\n",
        "\n",
        "      , sum(contribution_margin) as margin -- ê³µí—Œì´ìµ\n",
        "\n",
        "      ,sum(transport_cost_d2d) as d2d_cost -- ë¶€ë¦„ë°°ë°˜ë¹„ìš©\n",
        "\n",
        "  FROM `socar-data.soda_store.reservation_v2` r\n",
        "  LEFT JOIN socar-data.tianjin_replica.reservation_info i ON r.reservation_id = i.id\n",
        "  LEFT JOIN socar-data.tianjin_replica.reservation_dtod_info d ON r.reservation_id = d.reservation_id\n",
        "  LEFT JOIN `tianjin_replica.car_info` c ON r.car_id = c.id\n",
        "  LEFT JOIN `tianjin_replica.car_class` cl ON c.class_id = cl.id\n",
        "  WHERE 1=1\n",
        "  AND date >= '2023-11-06' AND date <= '2024-01-08'\n",
        "  AND r.member_imaginary IN (0,9)\n",
        "  AND region1 = 'ì œì£¼íŠ¹ë³„ìžì¹˜ë„'\n",
        "  GROUP BY date, way, region2\n",
        "  ORDER BY date, way, region2\n",
        "  \"\"\"\n",
        "\n",
        "df = pd.io.gbq.read_gbq(\n",
        "    query=query,\n",
        "    project_id=\"socar-data\"\n",
        ")"
      ],
      "metadata": {
        "id": "RiErlmAcLqLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "TOpjJWB_MqzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['region2'].unique()"
      ],
      "metadata": {
        "id": "3zgB03sDkYkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2T1SjdW3Mqwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "LUzScgnSMqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "zFXHsFyVOqP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', '{:1.0f}'.format)"
      ],
      "metadata": {
        "id": "782fWcR7OqNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['revenue_nuse'] = df['revenue'] / df['nuse'].replace({0: 1})  # 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€\n",
        "df['utime_nuse'] = df['utime'] / df['nuse'].replace({0: 1})  # 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€\n",
        "df['margin_nuse'] = df['margin'] / df['nuse'].replace({0: 1})  # 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€\n",
        "df['d2d_cost_nuse'] = df['d2d_cost'] / df['nuse'].replace({0: 1})  # 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€"
      ],
      "metadata": {
        "id": "qhmB20v2zOGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "krdzbhMTKrNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. ì œì£¼ì§€ì—­ì˜ ë¶€ë¦„ ìš´ì˜ ì‹œìž‘ì´í›„ ì™•ë³µ ì˜ˆì•½ ë¹„ì¤‘ì€ ìœ ì§€ë˜ê³  ìžˆëŠ”ì§€ ?   \n",
        "1-1 ì „ì²´ ê±´ìˆ˜ëŠ” ì¦ê°€ í•˜ì˜€ëŠ”ì§€ ?\n",
        "- ê±´ìˆ˜\n",
        "- ë§¤ì¶œ\n",
        "- ì´ìµ(GP)\n",
        "---"
      ],
      "metadata": {
        "id": "AMH9kWA1OwVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ê±´ìˆ˜, ì‹œê°„ì˜  ì˜ˆì•½íƒ€ìž…ë³„ êµ¬ì„±ë¹„*\n",
        "\n",
        "âœ” ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ê±´ìˆ˜ê°€ í™•ëŒ€ ë˜ì§€ ì•Šì•˜ë‹¤. (êµ¬ì„±ë¹„ëŠ” ë¹„ìŠ·í•˜ë‹¤)"
      ],
      "metadata": {
        "id": "ySmDJi1IO-Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ZkP5d75uylGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupby(['way', 'date'])[['nuse', 'utime']].sum().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = df_grouped.pivot(index='way', columns='date', values=['nuse', 'utime'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['nuse_growth'] = (df_pivot['nuse_To-be'] - df_pivot['nuse_As-is']) / df_pivot['nuse_As-is'] * 100\n",
        "df_pivot['utime_growth'] = (df_pivot['utime_To-be'] - df_pivot['utime_As-is']) / df_pivot['utime_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'nuse_As-is', 'nuse_To-be', 'nuse_growth', 'utime_As-is', 'utime_To-be', 'utime_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "1nE8u0HBjSJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.info()"
      ],
      "metadata": {
        "id": "E8WepaqYsJxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_totals = df.groupby('date')['nuse'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: dateì™€ wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì˜ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['nuse'].sum().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "summary['proportion'] = (summary['nuse'] / summary['nuse_total']) * 100"
      ],
      "metadata": {
        "id": "UBDmJijWYtYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary.info()"
      ],
      "metadata": {
        "id": "zQMxJt7nsWOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë¶„ë¦¬\n",
        "asis_data = summary[summary['date'] == 'As-is']\n",
        "tobe_data = summary[summary['date'] == 'To-be']\n",
        "\n",
        "# 'As-is' ë°ì´í„°ë¥¼ ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ 'To-be'ì™€ ëŒ€ì¹­ë˜ê²Œ ë§Œë“¦\n",
        "asis_data['nuse'] = asis_data['nuse'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['nuse'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    # marker=dict(color='rgba(55, 128, 191, 0.7)'),\n",
        "    text=-asis_data['nuse']  # í…ìŠ¤íŠ¸ëŠ” ì–‘ìˆ˜ë¡œ í‘œì‹œ\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['nuse'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    # marker=dict(color='rgba(255, 153, 51, 0.7)'),\n",
        "    text=tobe_data['nuse']\n",
        "))\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ nuse (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    title_font_size=22,\n",
        "    barmode='overlay',  # ë°”ê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì„¤ì •\n",
        "    bargap=0.1,  # ë°” ê°„ì˜ ê°„ê²©\n",
        "    xaxis=dict(\n",
        "        title='nuse ê±´ìˆ˜',\n",
        "        title_font_size=14,\n",
        "        tickvals=[i for i in range(-max(summary['nuse']), max(summary['nuse'])+1, int(max(summary['nuse'])/5))],\n",
        "        ticktext=[str(abs(i)) for i in range(-max(summary['nuse']), max(summary['nuse'])+1, int(max(summary['nuse'])/5))]\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…',\n",
        "        title_font_size=14\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XmiZPVLTQoTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', '{:1.0f}'.format)"
      ],
      "metadata": {
        "id": "dQ-ew2oiuaVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ì— ëŒ€í•´ ê°ê° nuseì˜ í•©ê³„ë¥¼ êµ¬í•©ë‹ˆë‹¤.\n",
        "total_nuse_asis = summary[summary['date'] == 'As-is']['nuse'].sum()\n",
        "total_nuse_tobe = summary[summary['date'] == 'To-be']['nuse'].sum()\n",
        "\n",
        "# ê° 'way'ë³„ 'nuse' í•©ê³„ì˜ ì „ì²´ í•©ê³„ ëŒ€ë¹„ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "asis_data['proportion'] = asis_data['nuse'] / total_nuse_asis\n",
        "tobe_data['proportion'] = tobe_data['nuse'] / total_nuse_tobe\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ëŒ€ì¹­ íš¨ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "asis_data['proportion'] *= -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ ë¹„ìœ¨ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['proportion'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    # ë¹„ìœ¨ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì •ìˆ˜ ë¶€ë¶„ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
        "    text=asis_data['proportion'].apply(lambda x: f\"{int(abs(x) * 100)}%\")\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì–‘ìˆ˜ ë¹„ìœ¨ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['proportion'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    # ë¹„ìœ¨ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì •ìˆ˜ ë¶€ë¶„ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
        "    text=tobe_data['proportion'].apply(lambda x: f\"{int(x * 100)}%\")\n",
        "))\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ nuse ë¹„ìœ¨ (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    title_font_size=22,\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='ë¹„ìœ¨',\n",
        "        title_font_size=14,\n",
        "        tickformat=',.0%'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…',\n",
        "        title_font_size=14\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yS1sbJ0dsHSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë¶„ë¦¬\n",
        "asis_data = summary[summary['date'] == 'As-is']\n",
        "tobe_data = summary[summary['date'] == 'To-be']\n",
        "\n",
        "# ë„ë„› ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Pie(labels=asis_data['way'],\n",
        "                     values=asis_data['proportion'],\n",
        "                     name='As-is',\n",
        "                     hole=0.4,  # ì¤‘ì•™ êµ¬ë©ì˜ í¬ê¸° ì„¤ì •\n",
        "                     domain={'x': [0, 0.48]},  # 'As-is'ë¥¼ ë„ë„› ì°¨íŠ¸ ì™¼ìª½ì— ë°°ì¹˜\n",
        "                     hoverinfo='label+percent+name'))\n",
        "\n",
        "fig.add_trace(go.Pie(labels=tobe_data['way'],\n",
        "                     values=tobe_data['proportion'],\n",
        "                     name='To-be',\n",
        "                     hole=0.4,\n",
        "                     domain={'x': [0.52, 1.0]},  # 'To-be'ë¥¼ ë„ë„› ì°¨íŠ¸ ì˜¤ë¥¸ìª½ì— ë°°ì¹˜\n",
        "                     hoverinfo='label+percent+name'))\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸ (ì œëª© ìœ„ì¹˜ ì¡°ì •)\n",
        "fig.update_layout(\n",
        "    title_text='As-is vs To-be ì˜ˆì•½íƒ€ìž…ë³„ nuseì˜ êµ¬ì„±ë¹„',\n",
        "    # ì°¨íŠ¸ ê°€ìš´ë° ì œëª© ëŒ€ì‹ ì— ì™¸ë¶€ì— í‘œì‹œ\n",
        "    annotations=[dict(text='As-is', x=0.1, y=1.15, font_size=16, showarrow=False),\n",
        "                 dict(text='To-be', x=0.9, y=1.15, font_size=16, showarrow=False)],\n",
        "    showlegend=True)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "T-7pSD25QVx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_totals = df.groupby('date')['utime'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: dateì™€ wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì˜ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['utime'].sum().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='utime', color='date',\n",
        "             title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ utime',\n",
        "             barmode='group',\n",
        "             text='utime',\n",
        "             labels={'utime': 'ì´ìš©ì‹œê°„', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kQydlOWKwfWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì¤€ë¹„: 'As-is'ì™€ 'To-be'ì˜ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary['proportion'] = summary['utime'] / summary['utime_total'] * 100\n",
        "\n",
        "# 'As-is' ë°ì´í„°ë¥¼ ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ëŒ€ì¹­ íš¨ê³¼ ìƒì„±\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "asis_data['proportion'] *= -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ì¤€ë¹„\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['proportion'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=asis_data['proportion'].apply(lambda x: f\"{abs(x):.2f}%\"),  # ì–‘ìˆ˜ ë¹„ìœ¨ë¡œ í…ìŠ¤íŠ¸ í‘œì‹œ\n",
        "    # marker_color='rgba(55, 128, 191, 0.7)'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì–‘ìˆ˜ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['proportion'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=tobe_data['proportion'].apply(lambda x: f\"{x:.2f}%\"),\n",
        "    # marker_color='rgba(255, 153, 51, 0.7)'\n",
        "))\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ utime êµ¬ì„±ë¹„ (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    title_font_size=22,\n",
        "    barmode='overlay',  # ë°”ê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì„¤ì •\n",
        "    bargap=0.1,  # ë°” ê°„ì˜ ê°„ê²©\n",
        "    xaxis=dict(\n",
        "        title='êµ¬ì„±ë¹„ (%)',\n",
        "        title_font_size=14,\n",
        "        tickformat=',.2f'  # ë¹„ìœ¨ í˜•ì‹ìœ¼ë¡œ ì¶• í‘œì‹œ\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…',\n",
        "        title_font_size=14,\n",
        "        categoryorder='total ascending'  # 'way'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_FnSWL8Kvamo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ì§€ì—­ë³„ ê±´ìˆ˜, ì‹œê°„ì˜ ì˜ˆì•½íƒ€ìž…ë³„ êµ¬ì„±ë¹„*\n",
        "\n",
        "âœ” ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ê±´ìˆ˜ê°€ í™•ëŒ€ ë˜ì§€ ì•Šì•˜ë‹¤. (êµ¬ì„±ë¹„ëŠ” ë¹„ìŠ·í•˜ë‹¤)"
      ],
      "metadata": {
        "id": "SCbeuGfnRfbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupby(['region2', 'way', 'date'])[['nuse', 'utime']].sum().reset_index()\n",
        "\n",
        "df_pivot = df_grouped.pivot_table(index=['region2', 'way'], columns='date', values=['nuse', 'utime'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "df_pivot['nuse_growth'] = (df_pivot['nuse_To-be'] - df_pivot['nuse_As-is']) / df_pivot['nuse_As-is'].replace(0, 1) * 100\n",
        "df_pivot['utime_growth'] = (df_pivot['utime_To-be'] - df_pivot['utime_As-is']) / df_pivot['utime_As-is'].replace(0, 1) * 100\n",
        "\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['region2', 'way', 'nuse_As-is', 'nuse_To-be', 'nuse_growth', 'utime_As-is', 'utime_To-be', 'utime_growth']]\n",
        "print(result_df)\n",
        "result_df"
      ],
      "metadata": {
        "id": "kDNAv_0Hlam4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "MD59y2FXvpqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['nuse'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['nuse'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='nuse', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ nuse',\n",
        "             barmode='group',\n",
        "             text='nuse',\n",
        "             labels={'nuse': 'ê±´ìˆ˜', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fiVFpIxfRluV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['nuse'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['nuse'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "summary['proportion'] = (summary['nuse'] / summary['nuse_total']) * 100\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='proportion', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ nuseì˜ êµ¬ì„±ë¹„',\n",
        "             barmode='group',\n",
        "             text='proportion',\n",
        "             labels={'proportion': 'êµ¬ì„±ë¹„ (%)', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Cb0oSshoO8uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì •ê·œí™”ë¥¼ ìœ„í•œ Scaler ì´ˆê¸°í™”\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# 'utime'ì— ëŒ€í•œ ì „ì²´ ë°ì´í„°ë¥¼ ì •ê·œí™”\n",
        "summary['nuse_normalized'] = scaler.fit_transform(summary[['nuse']])\n",
        "\n",
        "# 'date'ì™€ 'region2'ë³„ ì „ì²´ 'utime' ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°ì„ ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ìˆ˜ì •\n",
        "summary['nuse'] = summary['nuse_normalized']\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='nuse', color='date',\n",
        "             facet_col='region2',  # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ nuse (ì •ê·œí™”)',\n",
        "             barmode='group',\n",
        "             text='nuse',\n",
        "             labels={'nuse': 'ì´ìš©ê±´ìˆ˜ (ì •ê·œí™”)', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Cn-NeeWWFjws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['utime'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['utime'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='utime', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ utime',\n",
        "             barmode='group',\n",
        "             text='utime',\n",
        "             labels={'utime': 'ì´ìš©ì‹œê°„', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ov2Yddt4wwvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['utime'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['utime'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "summary['proportion'] = (summary['utime'] / summary['utime_total']) * 100\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='proportion', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ utimeì˜ êµ¬ì„±ë¹„',\n",
        "             barmode='group',\n",
        "             text='proportion',\n",
        "             labels={'proportion': 'êµ¬ì„±ë¹„ (%)', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YUB_I7J2w8PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì •ê·œí™”ë¥¼ ìœ„í•œ Scaler ì´ˆê¸°í™”\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# 'utime'ì— ëŒ€í•œ ì „ì²´ ë°ì´í„°ë¥¼ ì •ê·œí™”\n",
        "summary['utime_normalized'] = scaler.fit_transform(summary[['utime']])\n",
        "\n",
        "# 'date'ì™€ 'region2'ë³„ ì „ì²´ 'utime' ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°ì„ ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ìˆ˜ì •\n",
        "summary['utime'] = summary['utime_normalized']\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='utime', color='date',\n",
        "             facet_col='region2',  # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ utime (ì •ê·œí™”)',\n",
        "             barmode='group',\n",
        "             text='utime',\n",
        "             labels={'utime': 'ì´ìš©ì‹œê°„ (ì •ê·œí™”)', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4an-VJCRExyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ë§¤ì¶œê³¼ ê³µí—Œì´ìµì˜  ì˜ˆì•½íƒ€ìž…ë³„ êµ¬ì„±ë¹„*\n",
        "\n",
        "âœ” ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ê±´ìˆ˜ê°€ í™•ëŒ€ ë˜ì§€ ì•Šì•˜ë‹¤. (êµ¬ì„±ë¹„ëŠ” ë¹„ìŠ·í•˜ë‹¤)"
      ],
      "metadata": {
        "id": "sb1avRVWx4Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vJ6z6U94yCZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupby(['way', 'date'])[['revenue', 'margin']].sum().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = df_grouped.pivot(index='way', columns='date', values=['revenue', 'margin'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['revenue_growth'] = (df_pivot['revenue_To-be'] - df_pivot['revenue_As-is']) / df_pivot['revenue_As-is'] * 100\n",
        "df_pivot['margin_growth'] = (df_pivot['margin_To-be'] - df_pivot['margin_As-is']) / df_pivot['margin_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'revenue_As-is', 'revenue_To-be', 'revenue_growth', 'margin_As-is', 'margin_To-be', 'margin_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "QvJnvpbblvpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_totals = df.groupby('date')['revenue'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: dateì™€ wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì˜ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['revenue'].sum().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='revenue', color='date',\n",
        "             title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ revenue',\n",
        "             barmode='group',\n",
        "             text='revenue',\n",
        "             labels={'revenue': 'ë§¤ì¶œ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VW0JtqjCyBZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_totals = df.groupby('date')['margin'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: dateì™€ wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì˜ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['margin'].sum().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='margin', color='date',\n",
        "             title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ margin',\n",
        "             barmode='group',\n",
        "             text='margin',\n",
        "             labels={'revmarginenue': 'ê³µí—Œì´ìµ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2rD_okelyL0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'revenue'ì™€ 'margin'ì— ëŒ€í•œ dateë³„ ì´í•© ê³„ì‚°\n",
        "date_totals_revenue = df.groupby('date')['revenue'].sum().rename('revenue_total').reset_index()\n",
        "date_totals_margin = df.groupby('date')['margin'].sum().rename('margin_total').reset_index()\n",
        "\n",
        "# dateì™€ wayë³„ë¡œ 'revenue'ì™€ 'margin'ì˜ í•©ê³„ ê³„ì‚°\n",
        "summary_revenue = df.groupby(['date', 'way'])['revenue'].sum().reset_index()\n",
        "summary_margin = df.groupby(['date', 'way'])['margin'].sum().reset_index()\n",
        "\n",
        "# dateë³„ ì´í•©ê³¼ ë³‘í•©í•˜ì—¬ êµ¬ì„±ë¹„ ê³„ì‚°ì„ ìœ„í•œ ì¤€ë¹„\n",
        "summary_revenue = summary_revenue.merge(date_totals_revenue, on='date')\n",
        "summary_margin = summary_margin.merge(date_totals_margin, on='date')\n",
        "\n",
        "# êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary_revenue['revenue_proportion'] = (summary_revenue['revenue'] / summary_revenue['revenue_total']) * 100\n",
        "summary_margin['margin_proportion'] = (summary_margin['margin'] / summary_margin['margin_total']) * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ì¤€ë¹„: 'revenue'ì™€ 'margin' ì •ë³´ë¥¼ í•©ì¹˜ê¸°\n",
        "summary = pd.merge(summary_revenue, summary_margin[['date', 'way', 'margin', 'margin_proportion']], on=['date', 'way'])\n",
        "\n",
        "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ìµœì¢… ë°ì´í„°í”„ë ˆìž„ êµ¬ì„±\n",
        "result_df = summary[['date', 'way', 'revenue', 'revenue_proportion', 'margin', 'margin_proportion']]"
      ],
      "metadata": {
        "id": "X3Fr-4CVzmzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.info()"
      ],
      "metadata": {
        "id": "TAstJ-awzfbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "# ë‘ ê°œì˜ ë³‘ë ¬ ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ subplot ì„¤ì •\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=('Revenue Proportion', 'Margin Proportion'))\n",
        "\n",
        "# Revenue Proportion ì°¨íŠ¸ ì¶”ê°€\n",
        "for date in result_df['date'].unique():\n",
        "    df_filtered = result_df[result_df['date'] == date]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_filtered['way'], y=df_filtered['revenue_proportion'], name=f'Revenue {date}', text=df_filtered['revenue_proportion']),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# Margin Proportion ì°¨íŠ¸ ì¶”ê°€\n",
        "for date in result_df['date'].unique():\n",
        "    df_filtered = result_df[result_df['date'] == date]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_filtered['way'], y=df_filtered['margin_proportion'], name=f'Margin {date}', text=df_filtered['margin_proportion']),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Revenue and Margin by Date and Way\")\n",
        "fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Vy8fU0MC0jTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì •ê·œí™”ë¥¼ ìœ„í•œ Scaler ì´ˆê¸°í™”\n",
        "scaler_revenue = MinMaxScaler()\n",
        "scaler_margin = MinMaxScaler()\n",
        "\n",
        "# 'revenue'ì™€ 'margin'ì˜ ì •ê·œí™”\n",
        "summary['revenue_normalized'] = scaler_revenue.fit_transform(summary[['revenue']])\n",
        "summary['margin_normalized'] = scaler_margin.fit_transform(summary[['margin']])"
      ],
      "metadata": {
        "id": "3hTXIrunHDTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‘ ê°œì˜ ë³‘ë ¬ ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ subplot ì„¤ì •\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=('revenue_normalized', 'margin_normalized'))\n",
        "\n",
        "# ì •ê·œí™”ëœ Revenue ì°¨íŠ¸ ì¶”ê°€\n",
        "for date in summary['date'].unique():\n",
        "    df_filtered = summary[summary['date'] == date]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_filtered['way'], y=df_filtered['revenue_normalized'], name=f'Revenue {date}', text=df_filtered['revenue_normalized']),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# ì •ê·œí™”ëœ Margin ì°¨íŠ¸ ì¶”ê°€\n",
        "for date in summary['date'].unique():\n",
        "    df_filtered = summary[summary['date'] == date]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=df_filtered['way'], y=df_filtered['margin_normalized'], name=f'Margin {date}', text=df_filtered['margin_normalized']),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"ì •ê·œí™”ëœ Revenue and Margin by Date and Way\")\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "we1KRWLFHDQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ì§€ì—­ë³„ ë§¤ì¶œê³¼ ê³µí—Œì´ìµì˜  ì˜ˆì•½íƒ€ìž…ë³„ êµ¬ì„±ë¹„*\n",
        "\n",
        "âœ” ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ê±´ìˆ˜ê°€ í™•ëŒ€ ë˜ì§€ ì•Šì•˜ë‹¤. (êµ¬ì„±ë¹„ëŠ” ë¹„ìŠ·í•˜ë‹¤)"
      ],
      "metadata": {
        "id": "RabbynGUI_7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupby(['region2', 'way', 'date'])[['revenue', 'margin']].sum().reset_index()\n",
        "\n",
        "df_pivot = df_grouped.pivot_table(index=['region2', 'way'], columns='date', values=['revenue', 'margin'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "df_pivot['revenue_growth'] = (df_pivot['revenue_To-be'] - df_pivot['revenue_As-is']) / df_pivot['revenue_As-is'].replace(0, 1) * 100\n",
        "df_pivot['margin_growth'] = (df_pivot['margin_To-be'] - df_pivot['margin_As-is']) / df_pivot['margin_As-is'].replace(0, 1) * 100\n",
        "\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['region2', 'way', 'revenue_As-is', 'revenue_To-be', 'revenue_growth', 'margin_As-is', 'margin_To-be', 'margin_growth']]\n",
        "print(result_df)\n",
        "result_df"
      ],
      "metadata": {
        "id": "75lxJeVfmRal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['revenue'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['revenue'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='revenue', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ revenue',\n",
        "             barmode='group',\n",
        "             text='revenue',\n",
        "             labels={'revenue': 'ë§¤ì¶œ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wBGlVfhsyVRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ì˜ˆì œ ë°ì´í„° í”„ë ˆìž„ 'df'ê°€ ìžˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ revenueì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['revenue'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ revenueì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ revenue ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['revenue'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# revenueì— ëŒ€í•œ ì •ê·œí™”ë¥¼ ì§„í–‰\n",
        "scaler = MinMaxScaler()\n",
        "summary['revenue_normalized'] = scaler.fit_transform(summary[['revenue']])\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ì •ê·œí™”ëœ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='revenue_normalized', color='date',\n",
        "             facet_col='region2',  # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ revenue',\n",
        "             barmode='group',\n",
        "             text='revenue_normalized',\n",
        "             labels={'revenue_normalized': 'ì •ê·œí™”ëœ ë§¤ì¶œ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TOSEddGn4J-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['margin'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ nuseì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ nuse ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['margin'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='margin', color='date',\n",
        "             facet_col='region2', # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ margin',\n",
        "             barmode='group',\n",
        "             text='margin',\n",
        "             labels={'margin': 'ê³µí—Œì´ìµ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:1.0f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3M-6wSNKybZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ê³„ 1: dateì™€ region2ë³„ë¡œ marginì˜ í•©ê³„ë¥¼ ê³„ì‚°\n",
        "date_region2_totals = df.groupby(['date', 'region2'])['margin'].sum().reset_index()\n",
        "\n",
        "# ë‹¨ê³„ 2: date, region2, wayë³„ë¡œ marginì˜ í•©ê³„ë¥¼ ê³„ì‚° í›„, dateì™€ region2ì˜ ì¡°í•©ë³„ ì „ì²´ margin ê°’ì— ëŒ€í•œ êµ¬ì„±ë¹„ ê³„ì‚°\n",
        "summary = df.groupby(['date', 'region2', 'way'])['margin'].sum().reset_index()\n",
        "summary = summary.merge(date_region2_totals, on=['date', 'region2'], suffixes=('', '_total'))\n",
        "\n",
        "# marginì— ëŒ€í•œ ì •ê·œí™”ë¥¼ ì§„í–‰\n",
        "scaler = MinMaxScaler()\n",
        "summary['margin_normalized'] = scaler.fit_transform(summary[['margin']])\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ì •ê·œí™”ëœ ê²°ê³¼ ì‹œê°í™”\n",
        "fig = px.bar(summary, x='way', y='margin_normalized', color='date',\n",
        "             facet_col='region2',  # region2ë³„ë¡œ ì°¨íŠ¸ ë¶„í• \n",
        "             title='Date ë° Region2ë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ ê³µí—Œì´ìµ',\n",
        "             barmode='group',\n",
        "             text='margin_normalized',\n",
        "             labels={'margin_normalized': 'ì •ê·œí™”ëœ ê³µí—Œì´ìµ', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date', 'region2': 'Region2'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_mBX0oM62X69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *í•©ê³„ê°€ ì•„ë‹Œ ê±´ë‹¹ ì§€í‘œë¥¼ ë³´ëŠ” ê²ƒì´, íƒ€ë‹¹í•˜ë‹¤*\n",
        "- ê±´ë‹¹ ë§¤ì¶œ\n",
        "- ê±´ë‹¹ ì´ìš©ì‹œê°„\n",
        "- ê±´ë‹¹ ê³µí—Œì´ìµ\n",
        "\n",
        "âœ” ê±´ìˆ˜ë‚˜ ì‹œê°„ì´ í¬ê²Œ ëŠ˜ì–´ë‚˜ì§€ ì•Šì•˜ì§€ë§Œ\n",
        "1. ê±´ë‹¹ ì§€í‘œë“¤ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŒ\n",
        "\n",
        "ë¶€ë¦„ ì˜ˆì•½ì„ í™•ëŒ€í•  ìˆ˜ ìžˆë‹¤ë©´, ì „ì²´ ë§¤ì¶œê³¼ ì´ìµì„ ê°œì„ í•˜ëŠ”ê²Œ í° íš¨ê³¼ê°€ ìžˆì„ ê²ƒìœ¼ë¡œ ë³´ì—¬ì§"
      ],
      "metadata": {
        "id": "YRgqNhA3z4pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: date ë° dateì™€ wayë³„ë¡œ revenue_nuseì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['revenue_nuse'].mean().reset_index()\n",
        "date_totals = df.groupby('date')['revenue_nuse'].mean().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "df_grouped = df.groupby(['way', 'date'])['revenue_nuse'].mean().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = df_grouped.pivot(index='way', columns='date', values=['revenue_nuse'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['revenue_nuse_growth'] = (df_pivot['revenue_nuse_To-be'] - df_pivot['revenue_nuse_As-is']) / df_pivot['revenue_nuse_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'revenue_nuse_As-is', 'revenue_nuse_To-be', 'revenue_nuse_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "27t-mYt9moSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: date ë° dateì™€ wayë³„ë¡œ revenue_nuseì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['revenue_nuse'].mean().reset_index()\n",
        "date_totals = df.groupby('date')['revenue_nuse'].mean().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì²˜ë¦¬\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ 'revenue_nuse' ê°’ì„ ìŒìˆ˜ë¡œ ë³€í™˜\n",
        "asis_data['revenue_nuse'] = asis_data['revenue_nuse'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ê°’ ì‚¬ìš©, ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['revenue_nuse'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in -asis_data['revenue_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['revenue_nuse'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in tobe_data['revenue_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ë™ì ìœ¼ë¡œ xì¶• tickvalsê³¼ ticktext ìƒì„±\n",
        "max_value = max(tobe_data['revenue_nuse'].max(), -asis_data['revenue_nuse'].min())\n",
        "tick_step = int(max_value // 5) or 1\n",
        "tick_values = list(range(-int(max_value), int(max_value) + 1, tick_step))\n",
        "tick_texts = [str(abs(i)) for i in tick_values]\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ revenue_nuse (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Revenue per Use',\n",
        "        tickvals=tick_values,\n",
        "        ticktext=tick_texts\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…'\n",
        "    ),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_uWRHtzYTQg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# ë°ì´í„° ì¤€ë¹„ ë° ì •ê·œí™” ê³¼ì •\n",
        "# ì „ì²´ summary ë°ì´í„°ì—ì„œ 'revenue_nuse'ì˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "summary = df.groupby(['date', 'way'])['revenue_nuse'].mean().reset_index()\n",
        "\n",
        "# MinMaxScalerë¥¼ ì‚¬ìš©í•˜ì—¬ 'revenue_nuse'ì˜ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "scaler = MinMaxScaler()\n",
        "# ì •ê·œí™”ë¥¼ ìœ„í•´ 'revenue_nuse' ì—´ë§Œ í¬í•¨í•˜ëŠ” DataFrameì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "normalized_values = scaler.fit_transform(summary[['revenue_nuse']])\n",
        "# ì •ê·œí™”ëœ ê²°ê³¼ë¥¼ summaryì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "summary['revenue_nuse_normalized'] = normalized_values\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=-asis_data['revenue_nuse_normalized'],  # ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ 'As-is'ë¥¼ ì™¼ìª½ìœ¼ë¡œ í‘œì‹œ\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[f\"{-value:.2f}\" for value in asis_data['revenue_nuse_normalized']],  # ì •ê·œí™”ëœ ê°’ì„ ìŒìˆ˜ë¡œ í‘œì‹œ\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['revenue_nuse_normalized'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[f\"{value:.2f}\" for value in tobe_data['revenue_nuse_normalized']],\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ Revenue per Use (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Normalized Revenue per Use',\n",
        "        # ì •ê·œí™”ëœ ê°’ì˜ ë²”ìœ„ëŠ” -1ì—ì„œ 1ê¹Œì§€ì´ë¯€ë¡œ, tickvalsê³¼ ticktextë¥¼ ì¡°ì •í•  í•„ìš”ê°€ ìžˆìŠµë‹ˆë‹¤.\n",
        "        tickvals=[-1, 0, 1],\n",
        "        ticktext=['1', '0', '1']\n",
        "    ),\n",
        "    yaxis=dict(title='ì˜ˆì•½íƒ€ìž…'),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jYf7BVH66Lg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: date ë° dateì™€ wayë³„ë¡œ revenue_nuseì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['utime_nuse'].mean().reset_index()\n",
        "date_totals = df.groupby('date')['utime_nuse'].mean().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "df_grouped = df.groupby(['way', 'date'])['utime_nuse'].mean().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = df_grouped.pivot(index='way', columns='date', values=['utime_nuse'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['utime_nuse_growth'] = (df_pivot['utime_nuse_To-be'] - df_pivot['utime_nuse_As-is']) / df_pivot['utime_nuse_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'utime_nuse_As-is', 'utime_nuse_To-be', 'utime_nuse_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "_iXUaf0undqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì²˜ë¦¬\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ 'revenue_nuse' ê°’ì„ ìŒìˆ˜ë¡œ ë³€í™˜\n",
        "asis_data['utime_nuse'] = asis_data['utime_nuse'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ê°’ ì‚¬ìš©, ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['utime_nuse'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in -asis_data['utime_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['utime_nuse'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in tobe_data['utime_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ë™ì ìœ¼ë¡œ xì¶• tickvalsê³¼ ticktext ìƒì„±\n",
        "max_value = max(tobe_data['utime_nuse'].max(), -asis_data['utime_nuse'].min())\n",
        "tick_step = int(max_value // 5) or 1\n",
        "tick_values = list(range(-int(max_value), int(max_value) + 1, tick_step))\n",
        "tick_texts = [str(abs(i)) for i in tick_values]\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ utime_nuse (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Utime per Use',\n",
        "        tickvals=tick_values,\n",
        "        ticktext=tick_texts\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…'\n",
        "    ),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RD5SL9Dl0DmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScalerë¥¼ ì‚¬ìš©í•˜ì—¬ 'utime_nuse'ì˜ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "scaler = MinMaxScaler()\n",
        "# ì „ì²´ 'summary'ì— ëŒ€í•´ 'utime_nuse' ì—´ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ì •ê·œí™”ë¥¼ ì ìš©í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ìƒˆ ì—´ì— ì €ìž¥í•©ë‹ˆë‹¤.\n",
        "summary['utime_nuse_normalized'] = scaler.fit_transform(summary[['utime_nuse']])\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì •ê·œí™”ëœ ê°’ í• ë‹¹\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ ì •ê·œí™”ëœ 'utime_nuse' ê°’ì„ ìŒìˆ˜ë¡œ ë³€í™˜\n",
        "asis_data['utime_nuse_normalized'] = asis_data['utime_nuse_normalized'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ ì •ê·œí™”ëœ ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['utime_nuse_normalized'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[f\"{value:.2f}\" for value in -asis_data['utime_nuse_normalized']],  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì •ê·œí™”ëœ ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['utime_nuse_normalized'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[f\"{value:.2f}\" for value in tobe_data['utime_nuse_normalized']],  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ë™ì ìœ¼ë¡œ xì¶• tickvalsê³¼ ticktext ìƒì„± (ì •ê·œí™”ëœ ê°’ì˜ ë²”ìœ„ ê³ ë ¤)\n",
        "max_abs_value = max(abs(asis_data['utime_nuse_normalized'].min()), abs(tobe_data['utime_nuse_normalized'].max()))\n",
        "tick_values = [-max_abs_value, 0, max_abs_value]\n",
        "tick_texts = [f\"{-max_abs_value:.2f}\", \"0\", f\"{max_abs_value:.2f}\"]\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ Utime per Use (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Normalized Utime per Use',\n",
        "        tickvals=tick_values,\n",
        "        ticktext=tick_texts\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…'\n",
        "    ),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Mu-0SoFh6jgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: date ë° dateì™€ wayë³„ë¡œ revenue_nuseì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['margin_nuse'].mean().reset_index()\n",
        "date_totals = df.groupby('date')['margin_nuse'].mean().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "df_grouped = df.groupby(['way', 'date'])['margin_nuse'].mean().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = df_grouped.pivot(index='way', columns='date', values=['margin_nuse'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['margin_nuse_growth'] = (df_pivot['margin_nuse_To-be'] - df_pivot['margin_nuse_As-is']) / df_pivot['margin_nuse_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'margin_nuse_As-is', 'margin_nuse_To-be', 'margin_nuse_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "tdLmWjHkWjkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì²˜ë¦¬\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ 'revenue_nuse' ê°’ì„ ìŒìˆ˜ë¡œ ë³€í™˜\n",
        "asis_data['margin_nuse'] = asis_data['margin_nuse'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ê°’ ì‚¬ìš©, ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['margin_nuse'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in -asis_data['margin_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì •ìˆ˜ë¡œ í¬ë§·íŒ…)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['margin_nuse'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[int(value) for value in tobe_data['margin_nuse']],  # ì†Œìˆ˜ì  ì œê±°\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ë™ì ìœ¼ë¡œ xì¶• tickvalsê³¼ ticktext ìƒì„±\n",
        "max_value = max(tobe_data['margin_nuse'].max(), -asis_data['margin_nuse'].min())\n",
        "tick_step = int(max_value // 5) or 1\n",
        "tick_values = list(range(-int(max_value), int(max_value) + 1, tick_step))\n",
        "tick_texts = [str(abs(i)) for i in tick_values]\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ margin_nuse (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Margin per Use',\n",
        "        tickvals=tick_values,\n",
        "        ticktext=tick_texts\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…'\n",
        "    ),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pyPJhxWNWrAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScalerë¥¼ ì‚¬ìš©í•˜ì—¬ 'utime_nuse'ì˜ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
        "scaler = MinMaxScaler()\n",
        "# ì „ì²´ 'summary'ì— ëŒ€í•´ 'utime_nuse' ì—´ë§Œì„ ëŒ€ìƒìœ¼ë¡œ ì •ê·œí™”ë¥¼ ì ìš©í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ìƒˆ ì—´ì— ì €ìž¥í•©ë‹ˆë‹¤.\n",
        "summary['margin_nuse_normalized'] = scaler.fit_transform(summary[['margin_nuse']])\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„± ë° ì •ê·œí™”ëœ ê°’ í• ë‹¹\n",
        "asis_data = summary[summary['date'] == 'As-is'].copy()\n",
        "tobe_data = summary[summary['date'] == 'To-be'].copy()\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì˜ ì •ê·œí™”ëœ 'utime_nuse' ê°’ì„ ìŒìˆ˜ë¡œ ë³€í™˜\n",
        "asis_data['margin_nuse_normalized'] = asis_data['margin_nuse_normalized'] * -1\n",
        "\n",
        "# í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸ ìƒì„±\n",
        "fig = go.Figure()\n",
        "\n",
        "# 'As-is' ë°ì´í„° ì¶”ê°€ (ìŒìˆ˜ ì •ê·œí™”ëœ ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=asis_data['way'],\n",
        "    x=asis_data['margin_nuse_normalized'],\n",
        "    name='As-is',\n",
        "    orientation='h',\n",
        "    text=[f\"{value:.2f}\" for value in -asis_data['margin_nuse_normalized']],  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# 'To-be' ë°ì´í„° ì¶”ê°€ (ì •ê·œí™”ëœ ê°’ ì‚¬ìš©)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=tobe_data['way'],\n",
        "    x=tobe_data['margin_nuse_normalized'],\n",
        "    name='To-be',\n",
        "    orientation='h',\n",
        "    text=[f\"{value:.2f}\" for value in tobe_data['margin_nuse_normalized']],  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í‘œì‹œ\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# ë™ì ìœ¼ë¡œ xì¶• tickvalsê³¼ ticktext ìƒì„± (ì •ê·œí™”ëœ ê°’ì˜ ë²”ìœ„ ê³ ë ¤)\n",
        "max_abs_value = max(abs(asis_data['margin_nuse_normalized'].min()), abs(tobe_data['margin_nuse_normalized'].max()))\n",
        "tick_values = [-max_abs_value, 0, max_abs_value]\n",
        "tick_texts = [f\"{-max_abs_value:.2f}\", \"0\", f\"{max_abs_value:.2f}\"]\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(\n",
        "    title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ Margin per Use (í”¼ë¼ë¯¸ë“œ ì°¨íŠ¸)',\n",
        "    barmode='overlay',\n",
        "    bargap=0.1,\n",
        "    xaxis=dict(\n",
        "        title='Normalized Margin per Use',\n",
        "        tickvals=tick_values,\n",
        "        ticktext=tick_texts\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='ì˜ˆì•½íƒ€ìž…'\n",
        "    ),\n",
        "    legend=dict(title='Date')\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SPTJPEsh6xCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ë¶€ë¦„ ë¹„ìš©ì˜ í™•ëŒ€*\n",
        "- ë¶€ë¦„ ë°°ë°˜ë¹„ìš©\n",
        "- ê±´ë‹¹ ë¶€ë¦„ ë°°ë°˜ë¹„ìš©\n",
        "\n",
        "ê¸°ì¡´ê³¼ ê±°ì˜ ë¹„ìŠ·í•¨\n",
        "- ë¶€ë¦„ ì™•ë³µì—ì„œ ê°ì†Œëœ ë¹„ìš©ì´ ë¶€ë¦„ íŽ¸ë„ë¡œ ì¦ê°€"
      ],
      "metadata": {
        "id": "ga7zDYk7JAH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_d2d = df[df['way'].isin(['d2d_round', 'd2d_onway'])]\n",
        "\n",
        "# Step 2: date ë° dateì™€ wayë³„ë¡œ revenue_nuseì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['d2d_cost'].mean().reset_index()\n",
        "date_totals = df.groupby('date')['d2d_cost'].mean().reset_index()\n",
        "summary = summary.merge(date_totals, on='date', suffixes=('', '_total'))\n",
        "\n",
        "summary_grouped = summary.groupby(['way', 'date'])['d2d_cost'].sum().reset_index()\n",
        "\n",
        "# 'As-is'ì™€ 'To-be' ë°ì´í„°ë¥¼ wide formatìœ¼ë¡œ ë³€í™˜\n",
        "df_pivot = summary_grouped.pivot(index='way', columns='date', values=['d2d_cost'])\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "df_pivot.columns = [f'{i}_{j}' for i, j in df_pivot.columns]\n",
        "\n",
        "# ì¦ê°ë¥  ê³„ì‚°\n",
        "df_pivot['d2d_cost_growth'] = (df_pivot['d2d_cost_To-be'] - df_pivot['d2d_cost_As-is']) / df_pivot['d2d_cost_As-is'] * 100\n",
        "\n",
        "# ê²°ê³¼ ë°ì´í„°í”„ë ˆìž„ ìž¬êµ¬ì„±\n",
        "result_df = df_pivot.reset_index()\n",
        "result_df = result_df[['way', 'd2d_cost_As-is', 'd2d_cost_To-be', 'd2d_cost_growth']]\n",
        "result_df"
      ],
      "metadata": {
        "id": "QajyJsLvoclQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”, ì—¬ê¸°ì„œëŠ” revenue_nuseì˜ í‰ê· ì„ ì‚¬ìš©\n",
        "fig = px.bar(summary, x='way', y='d2d_cost', color='date',\n",
        "             title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ d2d_cost',\n",
        "             barmode='group',\n",
        "             text='d2d_cost',\n",
        "             labels={'d2d_cost': 'ë¶€ë¦„ ë°°ë°˜ë¹„ìš©', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date'})\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')  # ì†Œìˆ˜ì  ë‘ ìžë¦¬ë¡œ í¬ë§·\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7pghNV3Y7wqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# date ë° dateì™€ wayë³„ë¡œ d2d_costì˜ í‰ê·  ê³„ì‚°\n",
        "summary = df.groupby(['date', 'way'])['d2d_cost'].mean().reset_index()\n",
        "\n",
        "# MinMaxScaler ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# ì •ê·œí™”ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜\n",
        "def normalize_group(x):\n",
        "    return scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# ê° date ë³„ë¡œ ì •ê·œí™” ìˆ˜í–‰\n",
        "summary['d2d_cost_normalized'] = summary.groupby('date')['d2d_cost'].transform(normalize_group)\n",
        "\n",
        "# ë°” ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™”, ì •ê·œí™”ëœ d2d_cost í‰ê· ì„ ì‚¬ìš©\n",
        "fig = px.bar(summary, x='way', y='d2d_cost_normalized', color='date',\n",
        "             title='Dateë³„ ì˜ˆì•½íƒ€ìž…ë³„ ì •ê·œí™”ëœ d2d_cost í‰ê· ',\n",
        "             barmode='group',\n",
        "             text='d2d_cost_normalized',  # ì •ê·œí™”ëœ d2d_cost í‰ê·  í‘œì‹œ\n",
        "             labels={'d2d_cost_normalized': 'ì •ê·œí™”ëœ ë¶€ë¦„ ë°°ë°˜ë¹„ìš©', 'way': 'ì˜ˆì•½íƒ€ìž…', 'date': 'Date'})\n",
        "\n",
        "# ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ í…ìŠ¤íŠ¸ í¬ë§· ì§€ì •\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "uCqyab4vr-EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ë¶€ë¦„ íŽ¸ë„ ì˜¤í”ˆ/ì§€ì—­ í™•ëŒ€ ì „/í›„ ìœ íœ´ìœ¨ ë¹„êµ*\n",
        "- ì§€ì—­ í™•ëŒ€, íŽ¸ë„ ì˜¤í”ˆí›„ ìœ íœ´ìœ¨ ê°ì†Œì„¸   \n",
        "   ```23.12.22 í­ì„¤ ì´ìŠˆë¡œ ê¸‰ì¦í–ˆë˜ ì  ì°¸ê³ ```   \n",
        "\n",
        "âœ” ìœ íœ´ìœ¨ ê°œì„ ì— íš¨ê³¼ì "
      ],
      "metadata": {
        "id": "Y54XG6N7XgYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_idle = \"\"\"\n",
        "select\n",
        "  date,\n",
        "  CASE WHEN date BETWEEN '2023-11-06' AND '2023-12-07' THEN 'Before'\n",
        "       WHEN date BETWEEN '2023-12-08' AND '2024-01-08' THEN 'After' END as date_type,\n",
        "\n",
        "  round(sum(dp_min/(1440)),0) as total_car_cnt,\n",
        "  count(case when dp_min >0 and op_min = 0 then car_id end) as idle,\n",
        "  sum(op_min)/sum(dp_min) as op_rate,\n",
        "  count(case when dp_min >0 and op_min = 0 then car_id end)/round(sum(dp_min/(1440)),0) as idle_rate,\n",
        "  sum(dp_min)/60 as dp_hour,\n",
        "  sum(op_min)/60 as op_hour,\n",
        "  sum(bl_min)/60 as bl_hour,\n",
        "  sum(op_min_passport_subscription)/60 as p_hour\n",
        "\n",
        "from `socar-data.socar_biz.operation_per_car_daily_v2`\n",
        "where region1 in (\"ì œì£¼íŠ¹ë³„ìžì¹˜ë„\")\n",
        "and date >= '2023-11-06' and date <= \"2024-01-08\"\n",
        "and sharing_type in ('socar','zplus')\n",
        "and zone_id not in (122,2184,11480,12072,12097,10736,10738,11947,13787,13858,14494)\n",
        "group by date, date_type\n",
        "\"\"\"\n",
        "\n",
        "df_idle = pd.io.gbq.read_gbq(\n",
        "    query=query_idle,\n",
        "    project_id=\"socar-data\"\n",
        ")"
      ],
      "metadata": {
        "id": "K_Cu6pO7XoqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average idle_rate for each date_type\n",
        "avg_idle_rate = df_idle.groupby(['date', 'date_type'])['idle_rate'].mean().reset_index()\n",
        "\n",
        "# ì „/í›„ ìœ íœ´ìœ¨ê³¼ ë¶€ë¦„ ê±´ìˆ˜ í‰ê·  ë¶„í¬ë„ as a line graph\n",
        "fig = px.line(avg_idle_rate, x='date', y='idle_rate', color='date_type',\n",
        "              title='ì „/í›„ ìœ íœ´ìœ¨ ì¶”ì„¸ì„ ',\n",
        "              labels={'idle_rate': 'ì œì£¼ ì „ì²´ í‰ê·  ìœ íœ´ìœ¨'})\n",
        "\n",
        "# yì¶•ì˜ ë²”ìœ„ë¥¼ 0.0ì—ì„œ 0.2ìœ¼ë¡œ ì„¤ì •\n",
        "fig.update_layout(yaxis=dict(range=[0.0, 0.3]))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Z8pXBH-zXoh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ *ë¶€ë¦„ íŽ¸ë„ ì˜¤í”ˆ/ì§€ì—­ í™•ëŒ€ ì „/í›„ í•¸ë“¤ ìš´í–‰ë¥  ë¹„êµ*\n",
        "- ì§€ì—­ í™•ëŒ€, íŽ¸ë„ ì˜¤í”ˆí›„ í•¸ë“¤ ìš´í–‰ë¥  ìœ ì§€\n",
        "   ```ì§€ì—­ í™•ëŒ€ì™€ íŽ¸ë„ ì˜¤í”ˆì— ë”°ë¼ ë°°ë°˜ ì§€ì—°ì€ ì—†ìŒ```   \n",
        "\n",
        "âœ” ì°¨ëŸ‰ ë°°ë°˜ì— ë¬¸ì œ ì—†ìŒ"
      ],
      "metadata": {
        "id": "refJGv8ybB_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "  WITH base AS (\n",
        "    SELECT\n",
        "      r.id AS rid, /* ì˜¥ìŠ¤íŠ¸ë¼ ì˜ˆì•½ë²ˆí˜¸ */\n",
        "      r.state, /* í•¸ë“¤ì˜ ìƒíƒœê°’ 0:ì·¨ì†Œ, 3:ì™„ë£Œ */\n",
        "      hh.userId AS handler_num, /* í•¸ë“¤ëŸ¬ íšŒì›ë²ˆí˜¸ */\n",
        "      CASE WHEN r.member_id = 3806971 THEN 'í•¸ë“¤ëŸ¬'\n",
        "          WHEN r.member_id = 52846 THEN 'íƒì†¡ì—…ì²´' END AS member_type, /* í•¸ë“¤ëŸ¬/íƒì†¡ì—…ì²´ ìš´í–‰ êµ¬ë¶„ */\n",
        "\n",
        "      CASE WHEN r.way = 'd2d_export_h' THEN 'ë¶€ë¦„(ë°°ì°¨)'\n",
        "          WHEN r.way = 'd2d_import_h' THEN 'ë¶€ë¦„(ë°˜ì°¨)'\n",
        "          WHEN r.way = 'd2d_oneway' THEN 'ë¶€ë¦„íŽ¸ë„'\n",
        "          WHEN r.way = 'd2d_rev' THEN 'ë¶€ë¦„(ì§„í–‰ì „)'\n",
        "          WHEN r.way = 'd2d_round' THEN 'ë¶€ë¦„ì™•ë³µ'\n",
        "          WHEN r.way = 'handle' THEN 'í•¸ë“¤'\n",
        "          WHEN r.way = 'oneway' THEN 'íŽ¸ë„'\n",
        "          WHEN r.way = 'oneway_float' THEN 'íŽ¸ë„(í”Œë¡œíŒ…)'\n",
        "          WHEN r.way = 'return' THEN 'íšŒì†¡'\n",
        "          WHEN r.way = 'return_h' THEN 'íšŒì†¡(í•¸ë“¤)'\n",
        "          WHEN r.way = 'round' THEN 'ì™•ë³µ'\n",
        "          WHEN r.way = 'z2d_oneway' THEN 'ì¡´íŽ¸ë„' END as way,\n",
        "\n",
        "      date(r.start_at, \"Asia/Seoul\") as date,\n",
        "      date(ifnull(r.reserved_end_at, r.end_at), \"Asia/Seoul\") as return_at,\n",
        "\n",
        "      con.memo as memo, /* í•¸ë“¤ëŸ¬ ë¯¸ë§¤ì¹­ìœ¼ë¡œ íƒì†¡ì „í™˜ ëœ ê±´ì¸ì§€ í™•ì¸ ìš©ë„ */\n",
        "\n",
        "      cz.address /* ì˜ì¹´ì¡´ì˜ ì£¼ì†Œ, regionìœ¼ë¡œ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ìš´ ì§€ì—­ êµ¬ë¶„ ìš©ë„ */\n",
        "      ,r.way as parent_way,\n",
        "      timestamp_diff(hr.onboardat, hr.openat, minute) as dur\n",
        "\n",
        "    FROM `socar-data.tianjin_replica.reservation_info` AS r\n",
        "    LEFT JOIN `socar-handler.handler_replica.socarhandler_reservation` AS hr /* í•¸ë“¤ëŸ¬ ì˜ˆì•½ í…Œì´ë¸” (í•¸ë“¤ëŸ¬ ë°°ì •ëœ ë‚´ì—­ë§Œ ì ìž¬) */\n",
        "    ON hr.scReservationId = r.id\n",
        "    LEFT JOIN `socar-handler.handler_replica.socarhandler_handle` AS hh /* í•¸ë“¤ë³„ ì¶”ê°€ ì •ë³´ìš© í…Œì´ë¸” (í•¸ë“¤ëŸ¬ ë°°ì •ëœ ë‚´ì—­ë§Œ ì ìž¬) */\n",
        "    ON hh.reservationId = hr.reservationId\n",
        "    LEFT JOIN `socar-data.tianjin_replica.carzone_info` AS cz\n",
        "    ON cz.id = r.zone_id\n",
        "    LEFT JOIN (SELECT *\n",
        "                FROM `socar-data.tianjin_replica.reservation_memo`\n",
        "                WHERE memo LIKE '%íŒë§¤ëŒ€ê¸° ì œí•œì‹œê°„%') AS con /* ì˜¥ìŠ¤íŠ¸ë¼ ì˜ˆì•½ë©”ëª¨ ì¶”ì¶œ (íŠ¹ì • ë¬¸êµ¬ê°€ í¬í•¨ëœ ê±´ë“¤ì„ íƒì†¡ì—…ì²´ ì „í™˜ì´ë¼ê³  ë³´ê¸° ìœ„í•¨) */\n",
        "    ON con.info_key = r.id\n",
        "    WHERE r.way in ('d2d_export_h','d2d_import_h','handle') /* d2d_export_h ë°˜ì°¨: d2d_import_h ì´ë²¤íŠ¸í•¸ë“¤: handle */\n",
        "    AND r.state in (3,0) /* ì™„ë£Œ&ì·¨ì†Œ í•¸ë“¤ ì§‘ê³„ */\n",
        "    AND DATETIME(r.start_at,'Asia/Seoul') >= '2022-01-01'\n",
        "    AND (r.member_id = 3806971 OR (r.member_id = 52846 AND con.memo IS NOT NULL))\n",
        "    AND cz.region1 = 'ì œì£¼íŠ¹ë³„ìžì¹˜ë„'\n",
        "  ),\n",
        "\n",
        "  base2 AS (\n",
        "    SELECT\n",
        "      date(start_at, 'Asia/Seoul') as sdate,\n",
        "      way,\n",
        "      r.id as rid,\n",
        "      datetime_diff(end_at, start_at, hour) as dur\n",
        "\n",
        "    FROM `tianjin_replica.reservation_info` r LEFT JOIN `tianjin_replica.carzone_info` z ON r.zone_id = z.id\n",
        "    WHERE z.region1 = 'ì œì£¼íŠ¹ë³„ìžì¹˜ë„' AND r.member_imaginary IN (0, 9)\n",
        "                                    AND r.state IN (1, 2, 3) /* 1 ì˜ˆì•½ 2 ìš´í–‰ 3 ì™„ë£Œ */\n",
        "                                    AND r.way IN ('d2d_round', 'd2d_oneway')\n",
        "                                    AND date(start_at, 'Asia/Seoul') >= '2023-11-06'\n",
        "                                    AND date(start_at, 'Asia/Seoul') <= \"2024-01-08\"\n",
        "  ),\n",
        "\n",
        "  d2d_calc AS (\n",
        "    SELECT\n",
        "      sdate,\n",
        "      count(rid) as rev_cnt,\n",
        "      count(CASE WHEN way = 'd2d_round' THEN rid END) as round_rev,\n",
        "      count(CASE WHEN way = 'd2d_oneway' THEN rid END) as oneway_rev,\n",
        "      sum(dur) as dur,\n",
        "      sum(dur)/count(rid) as rev_dur,\n",
        "      sum(CASE WHEN way = 'd2d_round' THEN dur END) /count(CASE WHEN way = 'd2d_round' THEN rid END) as round_rev_dur,\n",
        "      sum(CASE WHEN way = 'd2d_oneway' THEN dur END) /count(CASE WHEN way = 'd2d_oneway' THEN rid END) as oneway_rev_dur\n",
        "    FROM base2\n",
        "    GROUP BY sdate\n",
        "  ),\n",
        "\n",
        "  handle_calc AS (\n",
        "    SELECT\n",
        "      date,\n",
        "      count(CASE WHEN way LIKE '%ë¶€ë¦„%' THEN rid END) as rev_total,\n",
        "      count(CASE WHEN member_type = 'í•¸ë“¤ëŸ¬' AND way LIKE \"%ë¶€ë¦„%\" THEN rid END) as handle_cnt,\n",
        "      count(CASE WHEN member_type = 'íƒì†¡ì—…ì²´' AND way LIKE \"%ë¶€ë¦„%\" THEN rid END) as local_cnt,\n",
        "      avg(dur) as d_minute,\n",
        "\n",
        "    FROM base\n",
        "    GROUP BY date\n",
        "  )\n",
        "\n",
        "  SELECT\n",
        "\n",
        "    dc.sdate,\n",
        "\n",
        "    CASE WHEN date >= '2023-11-06' AND date <= '2023-12-07' THEN 'As-is'\n",
        "        WHEN date >= '2023-12-08' AND date <= '2024-01-08' THEN 'To-be' END as date_type,\n",
        "\n",
        "    dc.rev_cnt,\n",
        "    dc.round_rev,\n",
        "    dc.oneway_rev,\n",
        "    round(dc.dur/dc.rev_cnt, 0) as rev_dur,\n",
        "    dc.round_rev_dur,\n",
        "    dc.oneway_rev_dur,\n",
        "\n",
        "    hc.rev_total,\n",
        "    hc.handle_cnt,\n",
        "    hc.local_cnt,\n",
        "    round(hc.d_minute, 0) as d_minute,\n",
        "    round(hc.handle_cnt/hc.rev_total, 2) as hanlde_rate\n",
        "\n",
        "  FROM d2d_calc dc LEFT JOIN handle_calc hc ON dc.sdate = hc.date\n",
        "  ORDER BY sdate desc\n",
        "  \"\"\"\n",
        "\n",
        "df_handle = pd.io.gbq.read_gbq(\n",
        "    query=query,\n",
        "    project_id=\"socar-data\"\n",
        ")\n",
        "\n",
        "df_handle.info()"
      ],
      "metadata": {
        "id": "5Kpp1z1_bBkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_handle = df_handle.groupby('date_type')['hanlde_rate'].mean().reset_index()\n",
        "avg_handle"
      ],
      "metadata": {
        "id": "9wdur4PxcAJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average idle_rate for each date_type\n",
        "avg_handle_rate = df_handle.groupby(['sdate', 'date_type'])['hanlde_rate'].mean().reset_index()\n",
        "\n",
        "# ì „/í›„ ìœ íœ´ìœ¨ê³¼ ë¶€ë¦„ ê±´ìˆ˜ í‰ê·  ë¶„í¬ë„ as a line graph\n",
        "fig = px.line(avg_handle_rate, x='sdate', y='hanlde_rate', color='date_type',\n",
        "              title='ì „/í›„ í•¸ë“¤ ìš´í–‰ë¥  ì¶”ì„¸ì„ ',\n",
        "              labels={'hanlde_rate': 'ì œì£¼ ì „ì²´ í‰ê·  í•¸ë“¤ ìš´í–‰ë¥ '})\n",
        "\n",
        "fig.update_layout(yaxis=dict(range=[0.4, 1.5]))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "K32xfQf0Xoe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… ì„œë¹„ìŠ¤ í™•ëŒ€í›„ ë§¤ì¶œê³¼ ì´ìš© ì¶”ì´\n",
        "- ì§€ì—­ í™•ëŒ€, íŽ¸ë„ ì˜¤í”ˆí›„ í•¸ë“¤ ìš´í–‰ë¥  ìœ ì§€\n",
        "   ```ì§€ì—­ í™•ëŒ€ì™€ íŽ¸ë„ ì˜¤í”ˆì— ë”°ë¼ ë°°ë°˜ ì§€ì—°ì€ ì—†ìŒ```   \n",
        "\n",
        "âœ” ì°¨ëŸ‰ ë°°ë°˜ì— ë¬¸ì œ ì—†ìŒ"
      ],
      "metadata": {
        "id": "7J4vjTTgl6P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7sHU-gEvwfTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í‰ê· ì„ ê³„ì‚°\n",
        "# ì´ ì˜ˆì œì—ì„œëŠ” sum()ì„ ì‚¬ìš©\n",
        "grouped_df = df.groupby(['date', 'way']).sum().reset_index()\n",
        "\n",
        "# 'date'ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê° ì§€í‘œë³„ë¡œ 'As-is'ì™€ 'To-be' ìƒíƒœë¥¼ ë¶„ë¦¬\n",
        "pivot_df = grouped_df.pivot(index='way', columns='date')\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚°\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[f'{metric}_To-be'] - pivot_df[f'{metric}_As-is']\n",
        "\n",
        "# ì¦ê° ë¹„êµ í‘œë¥¼ í™•ì¸\n",
        "print(pivot_df.reset_index()[['way'] + [f'{metric}_change' for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']]])\n",
        "pivot_df"
      ],
      "metadata": {
        "id": "zQysrh3Nl7Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# 1í–‰ 5ì—´ì˜ ì„œë¸Œí”Œë¡¯ êµ¬ì„±ì„ ìƒì„±\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "# ê° ì„œë¸Œí”Œë¡¯ì— ëŒ€í•´ ì¶• ë° ë ˆì´ì•„ì›ƒ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8cneY4E9mnSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í•©ê³„ë¥¼ ê³„ì‚°í•˜ë©´ì„œ, numeric_only=Trueë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •\n",
        "grouped_df = df.groupby(['date', 'way']).sum(numeric_only=True).reset_index()\n",
        "\n",
        "# pivot ëŒ€ì‹  pivot_table ì‚¬ìš©í•˜ê³  fill_value=0 ì§€ì •\n",
        "pivot_df = grouped_df.pivot_table(index='way', columns='date', values=['nuse', 'utime', 'revenue', 'margin', 'd2d_cost'], fill_value=0)\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚° (As-is ê°’ì´ 0ì¼ ê²½ìš° To-be ê°’ìœ¼ë¡œ ê³„ì‚°)\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    as_is_col = f'{metric}_As-is'\n",
        "    to_be_col = f'{metric}_To-be'\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[to_be_col] - pivot_df[as_is_col]\n",
        "\n",
        "# ì œì£¼ ì„œë¸Œí”Œë¡¯\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4GNMLONZ_7OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì œì£¼ì‹œ\n",
        "df_jeju = df[df['region2'] == 'ì œì£¼ì‹œ']\n",
        "\n",
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í‰ê· ì„ ê³„ì‚°\n",
        "grouped_df = df_jeju.groupby(['date', 'way']).sum().reset_index()\n",
        "\n",
        "# 'date'ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê° ì§€í‘œë³„ë¡œ 'As-is'ì™€ 'To-be' ìƒíƒœë¥¼ ë¶„ë¦¬\n",
        "pivot_df = grouped_df.pivot(index='way', columns='date')\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚°\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[f'{metric}_To-be'] - pivot_df[f'{metric}_As-is']"
      ],
      "metadata": {
        "id": "N2OU646BBjSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì œì£¼ ì„œë¸Œí”Œëž\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Jeju-Si Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "# ê° ì„œë¸Œí”Œë¡¯ì— ëŒ€í•´ ì¶• ë° ë ˆì´ì•„ì›ƒ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "umCRcIj_73as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì œì£¼ì‹œ ë°ì´í„° í•„í„°ë§\n",
        "df_jeju = df[df['region2'] == 'ì œì£¼ì‹œ']\n",
        "\n",
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í•©ê³„ë¥¼ ê³„ì‚°í•˜ë©´ì„œ, numeric_only=Trueë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •\n",
        "grouped_df = df_jeju.groupby(['date', 'way']).sum(numeric_only=True).reset_index()\n",
        "\n",
        "# pivot ëŒ€ì‹  pivot_table ì‚¬ìš©í•˜ê³  fill_value=0 ì§€ì •\n",
        "pivot_df = grouped_df.pivot_table(index='way', columns='date', values=['nuse', 'utime', 'revenue', 'margin', 'd2d_cost'], fill_value=0)\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚° (As-is ê°’ì´ 0ì¼ ê²½ìš° To-be ê°’ìœ¼ë¡œ ê³„ì‚°)\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    as_is_col = f'{metric}_As-is'\n",
        "    to_be_col = f'{metric}_To-be'\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[to_be_col] - pivot_df[as_is_col]\n",
        "\n",
        "# ì œì£¼ ì„œë¸Œí”Œë¡¯\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Jeju-Si Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mjGcab47_E3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„œê·€í¬ì‹œ\n",
        "df_swo = df[df['region2'] == 'ì„œê·€í¬ì‹œ']\n",
        "\n",
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í‰ê· ì„ ê³„ì‚°\n",
        "grouped_df = df_swo.groupby(['date', 'way']).sum().reset_index()\n",
        "\n",
        "# 'date'ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê° ì§€í‘œë³„ë¡œ 'As-is'ì™€ 'To-be' ìƒíƒœë¥¼ ë¶„ë¦¬\n",
        "pivot_df = grouped_df.pivot(index='way', columns='date')\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚°\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[f'{metric}_To-be'] - pivot_df[f'{metric}_As-is']"
      ],
      "metadata": {
        "id": "HDuJlwD4ASDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„œê·€í¬ ì„œë¸Œí”Œëž\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Seogwipo-Si Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "# ê° ì„œë¸Œí”Œë¡¯ì— ëŒ€í•´ ì¶• ë° ë ˆì´ì•„ì›ƒ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-PasXoU2ASAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„œê·€í¬ì‹œ í•„í„°ë§\n",
        "df_swo = df[df['region2'] == 'ì„œê·€í¬ì‹œ']\n",
        "\n",
        "# 'date'ì™€ 'way' ë³„ë¡œ ì§€í‘œë“¤ì˜ í•©ê³„ë¥¼ ê³„ì‚°í•˜ë©´ì„œ, numeric_only=Trueë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •\n",
        "grouped_df = df_swo.groupby(['date', 'way']).sum(numeric_only=True).reset_index()\n",
        "\n",
        "# pivot ëŒ€ì‹  pivot_table ì‚¬ìš©í•˜ê³  fill_value=0 ì§€ì •\n",
        "pivot_df = grouped_df.pivot_table(index='way', columns='date', values=['nuse', 'utime', 'revenue', 'margin', 'd2d_cost'], fill_value=0)\n",
        "\n",
        "# ì»¬ëŸ¼ ì´ë¦„ ìž¬ì •ì˜\n",
        "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# ì¦ê° ê³„ì‚° (As-is ê°’ì´ 0ì¼ ê²½ìš° To-be ê°’ìœ¼ë¡œ ê³„ì‚°)\n",
        "for metric in ['nuse', 'utime', 'revenue', 'margin', 'd2d_cost']:\n",
        "    as_is_col = f'{metric}_As-is'\n",
        "    to_be_col = f'{metric}_To-be'\n",
        "    pivot_df[f'{metric}_change'] = pivot_df[to_be_col] - pivot_df[as_is_col]\n",
        "\n",
        "# ì œì£¼ ì„œë¸Œí”Œë¡¯\n",
        "fig = make_subplots(rows=1, cols=5, subplot_titles=('Revenue Change', 'Margin Change', 'Nuse Change', 'Utime Change', 'D2d Cost Change'))\n",
        "\n",
        "# ê° ì§€í‘œë³„ë¡œ ì„œë¸Œí”Œë¡¯ì— ë°” ì°¨íŠ¸ ì¶”ê°€\n",
        "metrics = ['revenue', 'margin', 'nuse', 'utime', 'd2d_cost']\n",
        "for i, metric in enumerate(metrics, start=1):\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=pivot_df.index, y=pivot_df[f'{metric}_change'], name=f'{metric.capitalize()} Change'),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "# ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸\n",
        "fig.update_layout(height=600, width=1200, title_text=\"Seogwipo-Si Change from As-is to To-be across Metrics\", showlegend=False)\n",
        "fig.update_layout(barmode='group')\n",
        "\n",
        "# xì¶• ë° yì¶• ë ˆì´ë¸” ì—…ë°ì´íŠ¸\n",
        "fig.update_xaxes(title_text=\"Reservation Way\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Change\", row=1, col=1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "LIJd7jGzAR9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0p-BHe0Yzndx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ë¶€ë¦„ í™•ëŒ€ ì „/í›„ì˜ ë¶€ë¦„ì„ í˜¸ì¶œí•œ ì˜ˆì•½ì§€ ìœ„ì¹˜ ë³€í™”\n"
      ],
      "metadata": {
        "id": "oDZoMtZp1R5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "  SELECT\n",
        "      CASE WHEN date >= '2023-11-06' AND date <= '2023-12-07' THEN 'As-is'\n",
        "           WHEN date >= '2023-12-08' AND date <= '2024-01-08' THEN 'To-be' END as date,\n",
        "\n",
        "      scParentId as rid,\n",
        "      r.way,\n",
        "\n",
        "      -- hr.startlng, hr.startlat,\n",
        "      rv.dtod_start_lng as start_lng,\n",
        "      rv.dtod_start_lat as start_lat,\n",
        "      CASE WHEN hr.startaddress1 LIKE '%ì œì£¼ì‹œ%' THEN  'ì œì£¼ì‹œ'\n",
        "            WHEN hr.startaddress1 LIKE '%ì„œê·€í¬ì‹œ%' THEN  'ì„œê·€í¬ì‹œ' END as start_city,\n",
        "\n",
        "      -- hr.endlng, hr.endlat,\n",
        "      rv.dtod_end_lng as end_lng,\n",
        "      rv.dtod_end_lat as end_lat,\n",
        "      CASE WHEN hr.endAddress1 LIKE '%ì œì£¼ì‹œ%' THEN  'ì œì£¼ì‹œ'\n",
        "            WHEN hr.endAddress1 LIKE '%ì„œê·€í¬ì‹œ%' THEN  'ì„œê·€í¬ì‹œ' END as end_city,\n",
        "\n",
        "      rv.reservation_created_lat as c_lat,\n",
        "      rv.reservation_created_lng as c_lng,\n",
        "\n",
        "  FROM `socar-data.handler_replica.socarhandler_reservation` hr\n",
        "  LEFT JOIN `tianjin_replica.reservation_info` r ON hr.scParentId = r.id\n",
        "  LEFT JOIN `tianjin_replica.carzone_info` z ON r.zone_id = z.id\n",
        "  LEFT JOIN `soda_store.reservation_v2` rv ON hr.scParentId = rv.reservation_id\n",
        "  WHERE TIMESTAMP_TRUNC(created, DAY) BETWEEN '2023-11-06' AND '2024-01-08'\n",
        "  AND z.region1 = 'ì œì£¼íŠ¹ë³„ìžì¹˜ë„'\n",
        "  AND hr.way IN ('d2d_export_h')\n",
        "  AND r.state IN (1, 2, 3)\n",
        "  AND dtod_start_lng is not null\n",
        "  AND dtod_end_lng is not null\n",
        "  AND reservation_created_lat is not null\n",
        "  AND reservation_created_lng is not null\n",
        "  AND r.member_imaginary IN (0, 9)\n",
        "  \"\"\"\n",
        "\n",
        "df = pd.io.gbq.read_gbq(\n",
        "    query=query,\n",
        "    project_id=\"socar-data\"\n",
        ")\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e_icMoPa1Xoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'].unique()"
      ],
      "metadata": {
        "id": "M6bwKduO5s98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "# 'as-is'ì™€ 'to-be'ì— ëŒ€í•œ ìƒ‰ìƒ ì§ì ‘ ë§¤í•‘\n",
        "color_map = {\n",
        "    'As-is': 'blue',\n",
        "    'To-be': 'red'\n",
        "}"
      ],
      "metadata": {
        "id": "Ii6YyN2i3923"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§€ë„ì˜ ì´ˆê¸° ìœ„ì¹˜ì™€ ì¤Œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ ì§€ë„ ìƒì„±\n",
        "map = folium.Map(location=[df['start_lat'].mean(), df['start_lng'].mean()], zoom_start=10)\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆìž„ì„ ìˆœíšŒí•˜ë©° ë§ˆì»¤ ì¶”ê°€\n",
        "for _, row in df.dropna(subset=['date']).iterrows():\n",
        "    # color_mapì—ì„œ í•´ë‹¹ dateì— ëŒ€í•œ ìƒ‰ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "    marker_color = color_map[row['date']]\n",
        "    folium.Marker(\n",
        "        location=[row['start_lat'], row['start_lng']],\n",
        "        popup=f\"{row['date']}: {row['start_city']}\",\n",
        "        icon=folium.Icon(color=marker_color)\n",
        "    ).add_to(map)\n",
        "\n",
        "# ì§€ë„ í‘œì‹œ\n",
        "map"
      ],
      "metadata": {
        "id": "1olWOSnS3B46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from folium import plugins\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì— ëŒ€í•œ ì§€ë„\n",
        "as_is_df = df[df['date'] == 'As-is']\n",
        "as_is_map = folium.Map(location=[as_is_df['start_lat'].mean(), as_is_df['start_lng'].mean()], zoom_start=10)\n",
        "\n",
        "# 'As-is' ë°ì´í„°ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ìƒì„± ë° ë§ˆì»¤ ì¶”ê°€\n",
        "as_is_cluster = plugins.MarkerCluster().add_to(as_is_map)\n",
        "for _, row in as_is_df.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['start_lat'], row['start_lng']],\n",
        "        popup=f\"As-is: {row['start_city']}\",\n",
        "        icon=folium.Icon(color='blue')\n",
        "    ).add_to(as_is_cluster)\n",
        "\n",
        "# 'To-be' ë°ì´í„°ì— ëŒ€í•œ ì§€ë„\n",
        "to_be_df = df[df['date'] == 'To-be']\n",
        "to_be_map = folium.Map(location=[to_be_df['start_lat'].mean(), to_be_df['start_lng'].mean()], zoom_start=10)\n",
        "\n",
        "# 'To-be' ë°ì´í„°ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ìƒì„± ë° ë§ˆì»¤ ì¶”ê°€\n",
        "to_be_cluster = plugins.MarkerCluster().add_to(to_be_map)\n",
        "for _, row in to_be_df.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['start_lat'], row['start_lng']],\n",
        "        popup=f\"To-be: {row['start_city']}\",\n",
        "        icon=folium.Icon(color='green')\n",
        "    ).add_to(to_be_cluster)"
      ],
      "metadata": {
        "id": "qmVBWdtydC4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§€ë„ í‘œì‹œëŠ” ê°ê° ë³„ë„ë¡œ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\n",
        "as_is_map  # 'As-is' ì§€ë„ë¥¼ Jupyter Notebookì—ì„œ í‘œì‹œ"
      ],
      "metadata": {
        "id": "dyZ6aABbds3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_be_map  # 'To-be' ì§€ë„ë¥¼ Jupyter Notebookì—ì„œ í‘œì‹œ"
      ],
      "metadata": {
        "id": "VRiVVr1pdsX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§€ë„ì˜ ì´ˆê¸° ìœ„ì¹˜ì™€ ì¤Œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ ì§€ë„ ìƒì„±\n",
        "map = folium.Map(location=[df['c_lat'].mean(), df['c_lng'].mean()], zoom_start=10)\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆìž„ì„ ìˆœíšŒí•˜ë©° ë§ˆì»¤ ì¶”ê°€\n",
        "for _, row in df.dropna(subset=['date']).iterrows():\n",
        "    # color_mapì—ì„œ í•´ë‹¹ dateì— ëŒ€í•œ ìƒ‰ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "    marker_color = color_map[row['date']]\n",
        "    folium.Marker(\n",
        "        location=[row['c_lat'], row['c_lng']],\n",
        "        popup=f\"{row['date']}: {row['start_city']}\",\n",
        "        icon=folium.Icon(color=marker_color)\n",
        "    ).add_to(map)\n",
        "\n",
        "# ì§€ë„ í‘œì‹œ\n",
        "map"
      ],
      "metadata": {
        "id": "DJz3gMgM9B7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snOzcgsn4yTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}